\documentclass[a4paper]{proc}

\title{18 month progress report}
\author{Sherman Ip \quad Statistics \quad University of Warwick \quad March 31, 2017}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{graphicx}
\usepackage[outdir=./]{epstopdf}
\usepackage{natbib}
\usepackage{url}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{hyphenat}

\DeclareMathOperator{\expfamily}{ExpFamily}
\DeclareMathOperator{\expectation}{\mathbb{E}}
\DeclareMathOperator{\variance}{\mathbb{V}ar}
\DeclareMathOperator{\cov}{\mathbb{C}ov}
\DeclareMathOperator{\corr}{\mathbb{C}orr}
\DeclareMathOperator{\bernoulli}{Bernoulli}
\DeclareMathOperator{\betaDist}{Beta}
\DeclareMathOperator{\dirichlet}{Dir}
\DeclareMathOperator{\bin}{Bin}
\DeclareMathOperator{\MN}{Multinomial}
\DeclareMathOperator{\prob}{\mathbb{P}}
\DeclareMathOperator{\trace}{Tr}
\DeclareMathOperator{\normal}{N}
\DeclareMathOperator{\gammaDist}{Gamma}
\DeclareMathOperator{\poisson}{Poisson}

\newcommand{\RSS}{\mathrm{RSS}}
\newcommand{\euler}{\mathrm{e}}
\newcommand{\diff}{\mathrm{d}}
\newcommand{\T}{^\textup{T}}
\newcommand{\dotdotdot}{_{\phantom{.}\cdots}}
\newcommand{\BIC}{\textup{BIC}}

\newcommand{\vect}[1]{\mathbf{#1}}
\newcommand{\vectGreek}[1]{\boldsymbol{#1}}
\newcommand{\matr}[1]{\mathsf{#1}}

\begin{document}
\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}
3D printing, or additive layer manufacturing \cite{kodama1981automatic} \cite{wong2012review}, can be used to create objects with complicated shapes and geometry from a blueprint, or CAM model, on a computer.  Recently it has been commercialised and has served purposes in the medical field \cite{kang20163d} and engineering \cite{wong2012review}. The need for detecting defects from 3D printing is required in order to do quality control, especially if the 3D printed object is used for something critical for example body parts. 

X-ray computed tomography (CT) \cite{hounsfield1980computed} \cite{michael2001x} \cite{cantatore2011introduction} scans can be used to take images of a rotating 3D printed sample to obtain images of the sample at multiple angles. These x-ray images then can be combined to form a 3D projection and the detection of defects can start. However due to the random nature of x-ray photons in its production in an x-ray tube and attenuation from the x-ray tube to the detector, sources of error or noise is introduced. In order to do defect detection in a statistical manner, sources of error must be considered.

A mini-project on this topic was completed at 12 months of the PhD \cite{ip2016inside}. The main aim of that project was to conduct exploratory data analysis on a dataset of 100 images of an x-ray CT scan of a stationary 3D printed cuboid. Linear regressions were used to model the relationship between the variance and the mean grey value of each pixel. Separately latent variable models were fitted (or at least attempted) on the scans, such as PCA, factor analysis and the compound Poisson, to find sources of variance.

After the mini-project, the main aims during the PhD was to extend the mini-project by developing a statistic to aid in defect detection while considering the randomness of photons. Another aim was to build a model for the noise.

This report will outline a pre-process method called shading correction and it was investigated how it affected the mean and variance relationship. The mean and variance relationship was modelled using GLM with different link functions. After finding a good model for the mean and variance, a statistics was developed to compare two images in the face of uncertainty. Lastly the compound Poisson was studied.

\section{About the Data}
Data was collected prior to the mini-project. 20 black/grey/white (b/g/w) images were collected on 14/03/16 at around 1250. The b/g/w images are images obtained from the x-ray detector when exposed to x-rays at different settings, they are useful for calibrating the detector thus b/g/w images can be called reference images. About 2 hours later at 1503, 100 images of a 3D printed cuboid (or sample) were taken. These images were obtained from the x-ray detector when exposed to x-rays with the sample between the x-ray source and detector. The detector used was the Perkin Elmer XRD 1621 digital X-ray detector, with settings shown in Table \ref{table:settings}.

\begin{table*}
	\centering
	\begin{tabular}{c|c|c|c}
		& Voltage (kV) & Power (W) & Exposure time (ms) \\
		\hline
		Black & 0 & 0 & 1000\\
		Grey & 85 & 1.7 & 1000\\
		White & 85 & 6.8 & 1000 \\
		Sample & 100 & 33 & 500
	\end{tabular}
	\caption{Setting of the x-ray CT scan when collecting images from the x-ray detector. Error bars were not given and the number of significant figures shown are as given.}
	\label{table:settings}
\end{table*}

The images were $(1\,996\times1\,996)$ pixels in size and are in greyscale with 16 bits, in other words each pixel can have grey values which take integer values from 0 to $2^{16}-1$ inclusive. The grey values are in arbitrary units. The images are shown in Figure \ref{fig:image} and the histogram of grey values are shown in Figure \ref{fig:hist}.

\begin{figure*}
	\centering
	\includegraphics[width = 0.9\textwidth]{../figures/data/140316_image.eps}
	\caption{A black, grey, white and sample image obtained from the x-ray detector.}
	\label{fig:image}
\end{figure*}

\begin{figure}
	\centering
	\includegraphics[width = 0.45\textwidth]{../figures/data/140316_histo.png}
	\caption{A black, grey, white and sample image obtained from the x-ray detector.}
	\label{fig:hist}
\end{figure}

\section{Shading Correction}
The x-ray detector was made up 32 panels, arranged in 2 rows and 16 columns. Unfortunately these panels can be observed in the b/g/w images as a result of panel-wise effects in the image of the sample, as shown in Figure \ref{fig:image}. The effects can be described as introducing a gradient to the grey values within panels and perhaps between panels and globally. The aim of shading correction is to remove these effects to estimate the image of the scan if it were to have none of these effects.

Let $N(x,y)$ be the grey value of the pixel at position $(x,y)$ in the obtained image. Similarly let $U(x,y)$ be they grey value of pixels of the shading-free image. The shading effects can be modelled using a linear relationship
\begin{equation}
N(x,y) = U(x,y)b(x,y) + a(x,y)
\end{equation} 
where $b(x,y)$ is the multiplicative effect and $a(x,y)$ is the additive effect \cite{munzenmayer2003enhancing}. If it is possible to estimate the functions $b(x,y)$ and $a(x,y)$ using the estimators $\widehat{b}(x,y)$ and $\widehat{a}(x,y)$ respectively, then the shading-free image can be estimated using the estimator
\begin{equation}
\widehat{U}(x,y) = \frac{N(x,y)-\widehat{a}(x,y)}{\widehat{b}(x,y)} \times c_1 + c_2
\end{equation}
where $c_1$ and $c_2$ are some constants.
One method to estimate the images $b(x,y)$ and $a(x,y)$ is to use the mean black and white (b/w) images. Let $\overline{B}(x,y)$ and $\overline{W}(x,y)$ be the sample mean black and white images respectively, then the estimators for $b(x,y)$ and $a(x,y)$ are
\begin{equation}
\widehat{b}(x,y) = \overline{W}(x,y) - \overline{B}(x,y)
\end{equation}
and
\begin{equation}
\widehat{a}(x,y) = \overline{B}(x,y)
\end{equation}
respectively \cite{young2000shading}.

\subsection{Methods}
A new shading correction will be proposed here which extends the shading correction method described in the previous section by considering the grey images. The objective of shading correction is to predict the shading free image given the scan image, this can be done using linear regression of the form
\begin{equation}
U(x,y) = N(x,y)\beta(x,y)+\alpha(x,y) \ .
\end{equation}
The shading free image is not truly known, but one should expect the b/g/w shading free images should be completely flat. By using the obtained b/g/w images to estimate the parameters of the linear regression, this becomes a regression problem.

Let $R_\text{b}(x,y)$, $R_\text{g}(x,y)$ and $R_\text{w}(x,y)$ be the grey value of the pixel, at position $(x,y)$, of the sample mean b/g/w images respectively. Let these images have $h$ rows and $w$ columns. The shading free b/g/w images should be completely flat, in other words all the pixels should have the same grey value. A good guess what that grey value should be would be the sample mean of the grey values within the b/g/w images $\overline{R}_\text{b}$, $\overline{R}_\text{g}$ and $\overline{R}_\text{w}$ where
\begin{equation}
\overline{R}_j=\frac{\sum_{x=1}^w\sum_{y=1}^hR_j(x,y)}{n}
\end{equation}
for $j\in\{\text{b},\text{g},\text{w}\}$. By treating these within image sample mean grey values as the true shading free grey value, then the problem becomes a linear regression with 3 data points.

Let the global sample mean be
\begin{equation}
\overline{R}=\frac{\overline{R}_\text{b} + \overline{R}_\text{g} + \overline{R}_\text{w}}{3}
\end{equation}
and the between image sample mean to be
\begin{equation}
\overline{R}_B(x,y)=\frac{R_\text{b}(x,y) + R_\text{g}(x,y) + R_\text{w}(x,y)}{3} \ ,
\end{equation}
then the estimators for $\beta(x,y)$ and $\alpha(x,y)$ are
\begin{multline}
\widehat{\beta}(x,y)=
\\
\frac{\sum_{j\in\{\text{b},\text{g},\text{w}\}}\left(R_j(x,y)-\overline{R}_B(x,y)\right)\left(\overline{R}_j-\overline{R}\right)}{\sum_{j\in\{\text{b},\text{g},\text{w}\}}\left(R_j(x,y)-\overline{R}_B(x,y)\right)^2}
\end{multline}
and
\begin{equation}
\widehat{\alpha}(x,y) = \overline{R}-\widehat{\beta}(x.y)\overline{R}_B(x,y) 
\end{equation}
respectively.

Suppose now an image to be shading corrected is obtained $N(x,y)$. The shading free image $U(x,y)$ can be estimated by interpolating the linear regression
\begin{equation}
\widehat{U}(x,y) = \widehat{\beta}(x,y)N(x,y)+\widehat{\alpha}(x,y) \ .
\end{equation}
This can be extended to fewer or more than 3 reference images. The disadvantage of having more reference images is that it does cost time to take more scans. Shading correction which uses b/g/w images shall be referred to as b/g/w shading correction. Similarly shading correction which uses only the b/w images shall be referred to as b/w shading correction.

Figure \ref{fig:shadingCorrection} shows an example of a scan before and after b/g/w shading correction. By inspection, the post shading correction background is smoother because the panel effects appeared to be gone, meeting the objective of shading correction. Figure \ref{fig:shadingCorrection_grad} shows the values of $\widehat{\beta}(x,y)$. By inspection there is some curvature in the $\widehat{\beta}$ image, with high gradients in the corners, in addition to panel-wise gradients. Problems occur if the reference images behave differently from expected. For example some pixels may be dead and do not vary at all, this resulted in infinite gradients highlighted by red circles in the figure. In order to combat this, any pixels with undefined grey values post shading correction were replaced with the sample median of its 8 nearest neighbours.

\begin{figure*}
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/shadingCorrection/block.eps}
		\caption{Shading uncorrected}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/shadingCorrection/block_shadingCorrected.eps}
		\caption{b/g/w shading correction}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\includegraphics[width = \textwidth]{../figures/shadingCorrection/polynomial_shadingCorrection.eps}
		\caption{b/g/w 2nd order polynomial shading correction}
	\end{subfigure}
	\caption{A x-ray CT scan image before and after b/g/w shading correction.}
	\label{fig:shadingCorrection}
\end{figure*}

\begin{figure*}
	\centering
	\begin{subfigure}{0.45\textwidth}
		\includegraphics[width=\textwidth]{../figures/shadingCorrection/gradient.png}
		\caption{b/g/w shading correction}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\includegraphics[width=\textwidth]{../figures/shadingCorrection/polynomial_gradient.png}
		\caption{b/g/w 2nd order polynomial shading correction}
	\end{subfigure}
	\caption{The gradient used in b/g/w shading correction. Red circles indicate infinite gradient, green circles indicate negative gradient.}
	\label{fig:shadingCorrection_grad}
\end{figure*}

To avoid dealing with dead pixels \cite{brettschneider2014spatial}, a method was considered which smoothed the reference images prior to any shading correction parameter estimation. The purpose of this was to iron out any misbehaving pixels in the reference images and to capture the shading effects parametrically. Second order panel-wise surface polynomials were fitted to the b/g/w images, this is shown in Figure \ref{fig:polynomial_shadingCorrection}. The standardised residuals from the panel-wise fit are shown in Figure \ref{fig:polynomial_residual}. A quick inspection of the residuals shows any characteristics not captured by the panel-wise fit. In the black and grey images, the residuals show a global ring which is very unusual for the black image because it is detecting no x-rays at all. The b/g/w residuals all show vertical stripes. The panel-wise fit can be improved by including a global polynomial fit to capture between panel effects. Higher order polynomials can be considered but overfitting may be possible, as a result of higher order polynomials attempting to capture all the characteristics of the b/g/w images.

Shading correction which uses the fitted polynomials as reference images will be referred to as b/g/w 2nd order polynomial shading correction. The gradient parameter for the b/g/w 2nd order polynomial shading correction is shown in Figure \ref{fig:shadingCorrection_grad}. It is smoother and robust because the gradients are of sensible values, for example no infinite values. The resulting shading correction is shown in Figure \ref{fig:shadingCorrection}. This method can be advantageous as the panel-wise 2nd order polynomial only captures gradients of each panel and  smooths out clusters of bad behaving pixels as shown in the residuals. As a result, the shading correction is smoother between pixels because the bad behaving pixels do not impact as much in the interpolation of the linear regression.

\begin{figure*}
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/shadingCorrection/polynomial_black.eps}
		\caption{Black}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/shadingCorrection/polynomial_grey.eps}
		\caption{Grey}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/shadingCorrection/polynomial_white.eps}
		\caption{White}
	\end{subfigure}
	\caption{Second order panel-wise surface polynomials fit on the reference images.}
	\label{fig:polynomial_shadingCorrection}
\end{figure*}

\begin{figure*}
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/shadingCorrection/residual_black.png}
		\caption{Black}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/shadingCorrection/residual_grey.png}
		\caption{Grey}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/shadingCorrection/residual_white.png}
		\caption{White}
	\end{subfigure}
	\caption{Standardised residuals from the second order panel-wise surface polynomials fit on the reference images.}
	\label{fig:polynomial_residual}
\end{figure*}

\subsection{Experiments}

An experiment was conducted to assess the performance of shading correction. The methodology behind it is that shading correction applied on the reference images should remove shading effects and produce an image which is noisy but all the pixels should have the same mean grey value.

The 20 b/g/w images were spilt into a training set and test set of equal size randomly. The training set was used to estimate the parameters for shading corrections. Afterwards, shading correction was applied to each image in the test set producing 10 shading corrected reference images of each grey scale. The within pixel variance and between pixel variance was recorded, exactly the same as ANOVA treating each pixel as a group. For each pixel to have the same mean grey value, the within and between pixel variance should be similar. The experiment was repeated 20 times by repeating the assignment of the training and test set.

Figure \ref{fig:shadingCorr_bgw} shows a sample of reference images post shading correction. Without shading correction, the shading effects were clear. With b/w and b/g/w shading correction, the reference images appeared flatter. The flatness of the black and grey image depended if the grey images were used when training the shading correction. The b/g/w 2nd order polynomial shading correction retained some effects not captured by the panel wise polynomial fits. This can be tell because the shading corrected images were very similar to the residual plots in Figure \ref{fig:polynomial_residual}.

Table \ref{table:bgw_anova} shows the within and between pixel variance of the grey values. The table shown that b/w and b/g/w shading correction does make an improvement because it brings the within and between pixel variances closer together. The performance of shading correction on the black and grey images appeared to depend if the grey images were used in training the shading correction. The b/g/w 2nd order polynomial shading correction does perform by bringing the within and between pixel variances closer together but not as much as b/w and b/g/w shading correction.

\begin{figure*}
	\centering
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/shadingCorrection/shadingCorrection_no_shad.png}
		\caption{No shading correction}
	\end{subfigure}
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/shadingCorrection/shadingCorrection_bw.png}
		\caption{b/w shading correction}
	\end{subfigure}
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/shadingCorrection/shadingCorrection_bgw.png}
		\caption{b/g/w shading correction}
	\end{subfigure}
		\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/shadingCorrection/shadingCorrection_polynomial.png}
		\caption{b/g/w 2nd order polynomial shading correction}
	\end{subfigure}
	\caption{Shading correction applied on reference images from a test set. A training set was used to train the shading correction.}
	\label{fig:shadingCorr_bgw}
\end{figure*}

\begin{table*}
	\centering
	\begin{tabular}{c|c|c}
		\input{../tables/bgwShadingANOVA_no_shad.tex_table}
	\end{tabular}
	\\
	\vspace{.25cm}
	a) No shading correction
	\\\vspace{.5cm}
	\begin{tabular}{c|c|c}
		\input{../tables/bgwShadingANOVA_bw.tex_table}
	\end{tabular}
	\\
	\vspace{.25cm}
	b) b/w shading correction
	\\\vspace{.5cm}
	\begin{tabular}{c|c|c}
		\input{../tables/bgwShadingANOVA_bgw.tex_table}
	\end{tabular}
	\\
	\vspace{.25cm}
	c) b/g/w shading correction
	\\\vspace{.5cm}
	\begin{tabular}{c|c|c}
		\input{../tables/bgwShadingANOVA_polynomial.tex_table}
	\end{tabular}
	\\
	\vspace{.25cm}
	d) b/g/w 2nd order polynomial shading correction
	\caption{Quartiles of the within pixel and between pixel variance after 20 repeats of the experiment.}
	\label{table:bgw_anova}
\end{table*}

In conclusion, b/w and b/g/w shading correction do perform well because there was evidence they are attempting to iron out all the pixel grey values to have the same mean. The b/g/w 2nd order polynomial shading correction does its job. However because the panel wise polynomial under fitted and did not capture all the shading effects, the shading correction also did not capture all the shading effects.

The use of grey images in training the shading correction can be useful. It appeared that by considering the grey images, the shading correction performance on certain grey values was traded for other grey values.

Additional methods for shading correction could be considered such as fitting a global polynomial in addition to the panel wise polynomials to the reference images. There exist methods which do not require reference images at all, such as entropy minimisation \cite{likar2000retrospective}, which could be studied further and may be useful here.

\section{Mean/Variance Relationship}
The variance can be used to quantify the uncertainty of a grey value in a pixel. The purpose of modelling the mean and variance relationship of the grey value of a pixel is to be able to predict the grey value variance of each pixel for a single scan. This then can be used for inference when comparing a scan with the CAM model. A basic linear regression was conducted in the mini-project \cite{ip2016inside}, here generalised linear models (GLM) \cite{nelder1972generalized} \cite{mccullagh1984generalized} was used to model the mean and variance relationship.

The object of interest is the 3D printed sample. In the mini-project, it was found the background and the foam holding the 3D printed sample have different mean variance relationships \cite{ip2016inside}. Thus to model the mean variance relationship of the 3D printed sample, the 3D printed sample was segmented from the background and the foam. This was done by cropping the scans of the 3D printed sample in half, removing the bottom half containing the foam. Next a threshold was conducted using the following procedure: 
\begin{itemize}
	\item For each of the 20 b/g/w images, apply a panel wise median filter of size $3\times3$. Pixels outside the panels were symmetrically extended.
	\item Use these filtered reference images for shading correction.
	\item Take the mean over all shading corrected scans.
	\item Keep pixels with grey values less than $4.7\times 10^4$.
\end{itemize}
This method of segmentation was developed by informal experimentation. The resulting segmented image is shown in Figure \ref{fig:segment}. Other segmentation methods could be considered but further study of other methods may not be necessary here.

\begin{figure}
	\centering
	\includegraphics[width = 0.45 \textwidth]{../figures/meanVar/segment.eps}
	\caption{Resulting segmentation of the 3D printed sample}
	\label{fig:segment}
\end{figure}

The within pixel mean and variance grey value were estimated using the standard unbiased estimators. A few assumptions were made to justify the use of GLM to model the mean variance relationship. Firstly, it was assumed the standard error from estimating the mean was negligible. Secondly, it was assumed for a given pixel, the grey value from each scan were Normal i.i.d. Following from these assumptions, the sample variance is Gamma distributed with shape parameter $(n-1)/2$ where $n$ is the number of scans used to estimate the variance. Furthermore the standard error of the sample variance is proportional to $(n-1)^{-1/2}$, meaning the sample variance is more precise when more and more images were used to estimate the variance. This was experimentally shown in Figure \ref{fig:meanVar_sampleSize}, the spread of the sample variance decreased as $n$ increased.

GLM can model the sample variance as the response variable being Gamma distributed, explained by the sample mean through a link function $g(\text{variance})$. Fitting of the model was done using iterative re-weighted least squares. The dispersion parameter need not to be estimated because the shape parameter is known. A linear fit using the identity link did show that the Gamma response captured the spread of the sample variance for different sample means, this is shown in Figure \ref{fig:meanVar_sampleSize}.

\begin{figure*}
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/meanVar/sample_size_25.eps}
		\caption{$n=25$}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/meanVar/sample_size_50.eps}
		\caption{$n=50$}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/meanVar/sample_size_75.eps}
		\caption{$n=75$}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/meanVar/sample_size_100.eps}
		\caption{$n=100$}
	\end{subfigure}
	\caption{Mean and variance frequency density plot of each pixel's grey value in the segmented image of the 3D printed sample. The sample variance and sample mean were estimated using $n$ scans selected at random without replacement. A Gamma GLM was fitted with the identity link. The solid and dotted lines are the mean response and the $\Phi(\pm 1)$ quantiles respectively.}
	\label{fig:meanVar_sampleSize}
\end{figure*}

The systematic component is defined as a linear combination of the sample mean features, for example $\beta_0+\beta_1\text{mean}^p$ where $\beta_0$ and $\beta_1$ are constants to be estimated and $p$ is the polynomial order. In GLM, the link function equates to the systematic function to form a relationship between the mean and variance. 3 link functions were considered, identity, log and inverse, with the resulting mean and variance relationship shown in Table \ref{table:link_functions} and some fits in Figure \ref{fig:meanVar_link}.

\begin{table}
	\centering
	\begin{tabular}{c|c}
	Link function & Relationship \\
	\hline
	Identity & $\text{variance} = \beta_0+\beta_1\text{mean}^p$ \\
	Log & $\text{variance} = \exp{\left(\beta_0+\beta_1\text{mean}^p\right)}$ \\
	Inverse & $\text{variance} = \left(\beta_0+\beta_1\text{mean}^p\right)^{-1}$
	\end{tabular}
	\caption{Link functions and the resulting mean and variance relationship when using polynomial features.}
	\label{table:link_functions}
\end{table}

\begin{figure*}
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/meanVar/meanVar_identity.eps}
		\caption{Identity link, order 1}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/meanVar/meanVar_log.eps}
		\caption{Log link, order -1}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/meanVar/meanVar_canonical_1.eps}
		\caption{Inverse link, order -1}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/meanVar/meanVar_canonical_2.eps}
		\caption{Inverse link, order -2}
	\end{subfigure}
	\caption{Shading uncorrected mean and variance frequency density plot of each pixel's grey value in the segmented image of the 3D printed sample. A Gamma GLM was fitted with different link functions and polynomial order. The solid and dotted lines are the mean response and the $\Phi(\pm 1)$ quantiles respectively.}
	\label{fig:meanVar_link}
\end{figure*}

Different shading corrections had an effect on the mean variance relationship, as shown in Figure \ref{fig:meanVar_shadingCorrection}. Due to some misbehaving pixels in the reference images, grey value outliers were possible such as negative values. Pixels with grey values less than $5.8\times 10^3$ or more than $6.6\times 10^4$ were considered outliers. Outliers were replaced by the median of its 8 nearest neighbours.

\begin{figure*}
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/meanVar/shadingCorrection_no_shad.eps}
		\caption{No shading correction}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/meanVar/shadingCorrection_bw.eps}
		\caption{b/w shading correction}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/meanVar/shadingCorrection_bgw.eps}
		\caption{b/g/w shading correction}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/meanVar/shadingCorrection_polynomial.eps}
		\caption{b/g/w 2nd order polynomial shading correction}
	\end{subfigure}
	\caption{Post shading correction mean and variance frequency density plot of each pixel's grey value in the segmented image of the 3D printed sample. A Gamma GLM was fitted with the identity link. The solid and dotted lines are the mean response and the $\Phi(\pm 1)$ quantiles respectively.}
	\label{fig:meanVar_shadingCorrection}
\end{figure*}

\subsection{Experiments}

An experiment was conducted to assess the GLM fit on the mean and variance data for different link functions, polynomial orders and shading corrections.

For a given link function, polynomial order and shading correction, the 100 images of the 3D printed sample were spilt into two equally sized sets: the training set and the test set. The within pixel sample mean and sample variance  grey value was estimated for both the training set and test set separately. The GLM was fitted onto the mean/variance data obtained from the training set. The fitted model was then used to predict the variance given the mean on the test set. The predicted variance given the mean then can be compared with the sample variance.

Metrics such as the mean squared error can be used to assess how good the prediction is. However it should be noted that there is sampling error in the sample variance and the magnitude of the error varies for different means. In order to take the varying sampling error into account, the mean standardised squared error (MSSE) was used to assess the performance of the fitted GLM predicting the variance given the mean on the test set. The errors were standardised by dividing by the standard deviation of the GLM response.

The experiment was repeated 100 times by reassigning the training and test set.

The training and test MSSE are shown in Tables \ref{table:training} and \ref{table:test}. By using b/g/w shading correction, the test MSSE improved and suggests that b/g/w shading correction aids in variance prediction. b/w shading correction increased the MSSE by a magnitude of $\sim\times10^3$. A quick residual plot in Figure \ref{fig:glm_residual} showed that residuals were more centred at zero for b/g/w shading correction compared to b/w shading correction. 

The performance of the different link functions were very similar and no performance was gained by using higher order polynomials.

\begin{table*}
\centerline{
\begin{tabular}{c|c|c|c|c}
\input{../tables/GLM_meanVar_trainingTest_training.tex_table}
\end{tabular}}
\caption{Training mean squared standardised error from fitting GLM onto the mean/variance training set. Values stated are the quartiles from 100 repeats.}
\label{table:training}
\end{table*}

\begin{table*}
\centerline{
\begin{tabular}{c|c|c|c|c}
\input{../tables/GLM_meanVar_trainingTest_test.tex_table}
\end{tabular}
}
\caption{Test mean squared standardised error from using GLM to predict variance given mean from the test set. Values stated are the quartiles from 100 repeats.}
\label{table:test}
\end{table*}

\begin{figure*}
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/meanVar/residual_no_shad.eps}
		\caption{No shading correction}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/meanVar/residual_bw.eps}
		\caption{b/w shading correction}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width = \textwidth]{../figures/meanVar/residual_bgw.eps}
		\caption{b/g/w shading correction}
	\end{subfigure}
	\caption{Frequency density plot of the standardised residuals from predicting the variance given the mean of the test test using a training GLM with identity link function.}
	\label{fig:glm_residual}
\end{figure*}

In conclusion it was found that b/g/w shading correction aid in variance prediction by making the mean variance data more linear. A simple identity link perform just as well as other link function which suggests a linear relationship between the variance and the mean.

\section{$Z$ Statistic}

\section{Compound Poisson}

\bibliographystyle{unsrt}
\bibliography{../bib}

\end{document}
