The aim of this project is to obtain an x-ray image of a 3D printed sample and compare it with a simulation of that scan using software called \texttt{aRTist}. \texttt{aRTist} can simulate x-ray scans of the 3D printed sample given the specifications of the scan, such as the x-ray source, the x-ray detector and the blueprint of the 3D printed sample. Users of \texttt{aRTist} can align the simulated x-ray image to the real x-ray image using numerical methods, however this is outside the scope of this thesis.

Disagreement between the scan and \texttt{aRTist} can be found by simply subtracting one image from the other, any values too big in magnitude can be considered as a defect. However in the previous chapters, it was found that x-ray photons behave randomly and large differences in the comparison can be due to chance. Thus the comparisons should be done under the face of uncertainty.

A pixel by pixel inference was proposed to do defect detection. A statistic $z_{i,j}$ for the $(i,j)$ positioned pixel can be calculated for all pixels. This statistic is
\begin{equation}
    z_{i,j} = 
    \dfrac{
        \text{scan}_{i,j} - \text{aRTist}_{i,j}
    }
    {
        \sqrt{\widehat{\variance}\left[\text{scan}_{i,j}\right]}
    }
\end{equation}
where $\widehat{\variance}\left[\text{scan}_{i,j}\right]$ is the estimated grey value variance of pixel $(i,j)$ in the scan. Under mild assumptions, it was shown in the previous chapters that the grey values in the scan are Normal. Thus by treating the simulated image from \texttt{aRTist} as known, then
\begin{equation}
z_{i,j}\sim \normal(0,1) \ .
\end{equation}
This means the randomness of the $z_{i,j}$ statistics can be quantified.

The estimation of the grey value variance, that is $\widehat{\variance}\left[\text{scan}_{i,j}\right]$ will be explained here. The variance model can be calibrated, or trained, by holding out a number replicated x-ray scans of a 3D printed sample. These replicated x-ray scans provide variance-mean data which then can be used to train the variance model, such as a Gamma distributed GLM. The method on doing so was described in the previous chapter and it was found a linear relationship between the variance and the mean was a good model. The variance was then predicted using the grey value in the \texttt{aRTist} simulation.

This method for inference can be applied to the dataset \texttt{Sep16 120deg}. The 20 x-ray images were spilt into 2. 19 images were used to train the variance-mean model. One image, called the test image, was used to compare with \texttt{aRTist}, as shown in Figure \ref{fig:inference_scan_aRTist}.

\begin{figure}
	\centering
    \centerline{
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{../figures/inference/scan.eps}
        \caption{X-ray image}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{../figures/inference/aRTist.eps}
        \caption{\texttt{aRTist} simulation}
    \end{subfigure}
    }
    \caption{An x-ray scan of a 3D printed cuboid, from the \texttt{Sep16 120deg} dataset. This can be compared directly to the \texttt{aRTist} simulation for defects.}
    \label{fig:inference_scan_aRTist}
\end{figure}

For each pixel, a $z_{i,j}$ statistic was calculated. A $z_{i,j}$ statistic too large in magnitude can be considered to be evidence of a positive result. Another way to represent the $z_{i,j}$ statistic is the $p$-value which is given as
\begin{equation}
    p_{i,j} = 2(1-\Phi(\|z_{i,j}\|))
\end{equation}
which can takes values $0\leqslant p_{i,j} \leqslant 1$. A $p$-value too small is considered to be evidence of a positive result. The result $z$ statistics and $p$-values are shown in Figure \ref{fig:logp_z}.

\begin{figure}
	\centering
    \centerline{
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{../figures/inference/logp.eps}
        \caption{$-\log p\text{-values}$}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{../figures/inference/z_image.eps}
        \caption{$z$ statistics}
    \end{subfigure}
    }
    \caption{The resulting z statistics and $p$ values comparing an x-ray scan with the \texttt{aRTist} simulation.}
    \label{fig:logp_z}
\end{figure}

The resulting $z$ statistics and $p$-values are concerning. This is because the $p$-values are not very smooth on the surfaces of the sample. It should be expected that small $p$-values are in areas of the defects. Significant pixels were chosen for $\|z\|>\input{../figures/inference/z_critical.txt}$, this value was chosen by using the \cite{benjamini1995controlling} algorithm at the $z_\alpha = 2$ significance level. The significant pixels are shown in Figure \ref{fig:sig_pixels}.

This proposed method for defect detection failed because too many false positives were detected. These false positives appear to have some structure, for example clustering in the corners or on surfaces. In addition, false negatives were detected because not all of the defects were detected.

Model misspecification appears to be the main source of error. The $z$ statistics can be inspected using a histogram, as shown in Figure \ref{fig:z_histo}. The histogram of the $z$ statistics do not look Normal which seems to suggest that the assumption of $z_{i,j}\sim \normal(0,1)$ is incorrect. However this assumption can relaxed and can be done using the empirical null \citep{efron2004large}.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{../figures/inference/sig_pixels.eps}
    \caption{Signficiant pixels highlighted at the $z_\alpha = 2$ significance level.}
    \label{fig:sig_pixels}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{../figures/inference/z_histo.eps}
    \caption{Histogram of the $z$ statistics}
    \label{fig:z_histo}
\end{figure}

This chapter will cover hypothesis testing, for a single test and then for multiple tests. The empirical null will then be reviewed which then can be extended to an image filter, called the empirical null filter. This filter will adjust each $z$ statistic according to its neighbours, ironing out false positive results. Simulations and actual results will be shown at the end of the chapter.

\section{Hypothesis Testing}

Hypothesis testing dates back to \cite{pearson1900on}, \cite{neyman1933on} and \cite{fisher1970statistical}. It is so fundamental in science that it is now taught in schools.

The focus on this section is on the single hypothesis test. Here the random variable $Z\sim\normal(\mu,1)$ will be studied here as this is of interest in this project. It also appears in other tests such as the difference in sample means.

In the context of this project, an example of hypothesis testing will be given here. Here, it was assumed that $Z\sim\normal(0,1)$. A null hypothesis can be written down to describe this
\begin{equation}
    H_0:\mu=0 \ .
\end{equation}
It specifies the assumptions made on the random variable $Z$. Any data behaving as assumed is treated as a negative result.

A positive result is obtained when unlikely data is obtained and this happens if $Z$ deviates too much from 0. This can be described as testing $H_0$ against an alternative hypothesis $H_1$ where
\begin{equation}
    H_1:\mu\neq0 \ .
\end{equation}
How much $Z$ deviates from 0 to be considered a positive is up to the user but typically $\|Z\|>z_\alpha$ where $z_\alpha =2$ is considered significant.

A way to quantify the threshold for a positive result is to use something called the size of the test, otherwise known as the significance level, denoted as $\alpha$. This is the probability of a false positive result, which can be denoted as
\begin{equation}
    \prob(\|Z\|>z_\alpha|H_0) = \alpha \ .
\end{equation}
Using the fact the Normal distribution is symmetric then
\begin{equation}
    2(1 - \Phi(z_\alpha)) = \alpha \ .
    \label{eq:inference_single_alpha}
\end{equation}
The choice of $z_\alpha=2$ will set the size of the test to be $\alpha\approx 4.55\%$. This sort of choice of threshold and size is sensible.

The $p$-value is a way to represent an observation of the data $Z=z$. Similar to the size, the $p$-value is
\begin{equation}
    p=2(1-\Phi(\|z\|)) \ .
\end{equation}
As a result, the $p$-value can be compared directly to the size of the test. That is there is a positive result if $p<\alpha$, otherwise it is a negative result.

The power of the test is defined as the probability of a true positive result. For unknown $\mu$, it is useful to investigate the power for a range of $\mu$.

\section{Multiple Hypothesis Testing}

\section{Empirical Null}

\section{Empirical Null Filter}

\section{Results}