One of the first methods of additive manufacturing (AM) is stereolithography \citep{kodama1981automatic, hull1986apparatus, 3d2019our} which involves the curing of a photosensitive resin using an ultraviolet laser. The technology has evolved and AM is capable of manufacturing objects with complicated internal and external geometries. However, there is a need for product inspection and in particular assessing the quality of the internal structures.

Imaging using x-rays \citep{rontgen1896on} have been used in the medical field. In x-ray computed tomography \citep{cormack1973reconstruction, hounsfield1973computerized, hounsfield1980computed}, the patient has an x-ray image taken at multiple angles. These x-ray images are used to reconstruct what was taken in 3D in order to make a diagnostic.

X-ray computed tomography (XCT) can be used as a non-destructive test for additive manufactured objects, this is the main theme of this thesis. Various reviews on additive manufacturing exist such as \cite{kruth1991material, kruth1998progress, pham1998comparison, gibson2010additive, wong2012review, ngo2018additive}. For XCT used in manufacturing, there are \cite{cantatore2011introduction, kruth2011computed, sun2012overview}. \cite{thompson2016x} reviewed the applications of XCT on AM.

In this chapter, AM is reviewed followed by XCT. The latest research for the use of XCT on AM is reviewed at the end of the chapter.

\section{Additive Manufacturing}

Loosely, AM involves solidifying material onto a moving platform so that the object is manufactured layer by layer. Typically this is a slow and expensive method compared to destructive methods such as drilling and cutting for example. However, this is not the full picture. The set up cost for AM is low, in particular destructive methods requires planning and setting up various apparatus before the manufacturing stage \citep{gibson2010additive}. This is why AM used to be called rapid prototyping \citep{kruth1991material}, it was suitable to manufacture bespoke items.

Various different AM technologies were invented during the advancement of AM. Because of this, there are various applications of AM, for example in medical and biomedical sciences \citep{kang20163d, kourra2018computed}, engineering \citep{cooper2015design}, food engineering \citep{godoi20163d} and art \citep{ornes2013mathematics, grossman2019bathsheba}.

\subsection{Additive Manufacturing Technologies}

The different AM technologies can be classified based on the apparatus, for example liquid based or power based, and/or on the method of manufacturing, for example point by point or layer by layer \citep{kruth1991material}. The liquid based AM technologies presented here are stereolithography \citep{kodama1981automatic, hull1986apparatus, 3d2019our} and fused deposition modelling \citep{crump1991fused, crump1992apparatus, stratasys2019what}. The following power based technologies are presented here: 3D printing \citep{sachs1990three}, selective laser sintering \citep{deckard1989method, dtm1990the, 3d2019our}, electron beam melting \citep{larsson2004arrangement, arcam2019history}, laser engineered net shaping \citep{atwood1998laser}.

Stereolithography is a liquid based AM technology. It consist of a container containing a liquid photo-hardening monomer or polymer as well as a piston and platform which holds and moves the manufactured product up and down. A laser with a specific wavelength, typically \SIrange{300}{400}{\nano\metre} \citep{kodama1981automatic}, is emitted onto a point of the surface of the liquid and solidifies. The laser is controlled by a computer to solidified specific parts of the liquid surface. The platform is lowered and the cycle repeats, manufacturing the object layer by layer. Laser absorption happens a few tenths of a millimetre which corresponds to the thickness of each layer \citep{kruth1991material, pham1998comparison}.

Fused deposition modelling is another liquid based AM technology. A jetting head, or nozzle, deposit the molten material onto a platform or on top of the previous layer. The material is usually plastic in a form of a thin filament. It is heated to just above its melting points, typically \SI{1}{\degreeCelsius} \citep{crump1992apparatus}, so that it cools down within \SI{0.1}{\second} \citep{kruth1991material}. The platform moves, and controlled by a computer, in the $x-y$ axis, or left to right and front to back, to produce a layer. The jetting head can move in the $z$ axis, or up and down, to manufacture the next layer. In the original patent by \cite{crump1992apparatus}, the thickness can be as thin as 0.0001 inches (\SI{0.003}{\milli\metre}).

3D printing is a powder based AM technology. A jetting head deposit a binding agent in droplets onto a bed of powder of ceramic, metal or polymer. The binding agent is cured via evaporation or heating which glues the powder particles together. The bed can move in all 3 dimensions and the object is manufactured layer by layer. The binding agent must have low viscosity so it can be deposited, it may also be charged so that it can be deflected using an electric field for precise deposition \citep{sachs1990three}. The thickness of each layer is determined by the size of the droplets of the binding agent, which can be as small as \SI{15}{\micro\metre} in diameter \citep{sachs1990three}. \cite{sachs1990three} reported a tolerance of 0.001 inches (\SI{0.03}{\milli\metre}).

Selective laser sintering, electron beam melting and laser engineered net shaping are powder based AM technology. Selective laser sintering is similar to 3D printing but instead a laser is used to sinter or fuse the powder particles together. This is done in a chamber heated just below the melting point of the material \citep{wong2012review}. Various materials such as metal and plastics can be used \citep{wong2012review}. Electron beam melting is similar but instead an electron beam is used instead of a laser and this is done in a high vacuum chamber to avoid oxidation \citep{wong2012review}. In laser engineered net shaping, a powder bed is not used; instead the powder is deposited on the desired location and then melted using a laser. This is a popular method to manufacture metal objects \citep{gibson2010additive}.

There are many more AM technologies but they can be found in numerous review literatures. A comparison of the mentioned AM technologies available at the time were done by \cite{pham1998comparison, kim2008benchmark}. Factors such as material cost, mechanical properties and the resolution of the manufacturing were considered. There are also safety aspects to assess, for example powder in powder based methods can escape into the environment and the liquid used in stereolithography is toxic, sticky and has spilling risk \citep{kim2008benchmark}. This makes fused deposition modelling a popular choice and can be used in an office environment \citep{ngo2018additive}.

The strength of the manufactured object vary from geometry to geometry but also from direction to direction. Because the manufactured object was made layer by layer, the strength varies if the load was applied in the building direction (vertical) or the scanning direction (horizontal) \citep{kim2008benchmark}. Experimental results shown that fused deposition modelling has superior strength in the scanning direction but weak in the building direction \citep{kim2008benchmark}.

The strongest manufactured methods were found to be powder based methods and stereolithography, however they are slow and material costs are high \citep{kim2008benchmark}. Fused deposition modelling has low costs and high speeds but suffers from weak mechanical properties \citep{ngo2018additive}.

The materials available for each AM technology varies. The materials used in stereolithography is limited because of the use of liquids with photo-hardening properties \citep{ngo2018additive}. Fused deposition modelling is limited to plastics \citep{ngo2018additive}. Selective laser sintering and laser engineered net shaping can manufacture objects using metals such as aluminium alloys, steel, titanium and titanium alloys \citep{herzog2016additive}.

\subsection{Pre/Post Processing}

The blueprint of the object to be manufactured is called a computer-aided design (CAD). For it to be processed by an AM apparatus, the CAD is converted to a STL file \citep{3d1989sterolithography, 3d2019what} which represent surfaces made up of series of triangles. STL stands for sterolithography but could also be called standard tessellation language \citep{wong2012review}. Some accuracy is lost here as the surface of the CAD is represented approximately by triangles \citep{gibson2010additive}. The STL file is then sliced into layers \citep{jamieson1995direct, vatani2009enhanced} so that the AM apparatus knows what to build for each layer.

When the AM object is manufactured, post processing techniques can be done at this stage. For example sanding may be done to smooth the surfaces \citep{gibson2010additive}. The manufactured object may be inspected for pores or defects by comparing the x-ray image of the object with the CAD \citep{lee2015compliance, villarraga2015assessing, kim2016inspection}. This will be reviewed in the second half of this chapter.

As with any apparatus, regular maintenance is required \citep{bell2014maintaining}.

\subsection{Online Inspection and Defects}

The manufacturing process can be monitored, this is called online or in-situ process monitoring \citep{everton2016review}. The idea is that problems in the manufacturing is found as soon as possible before the final product is spoiled \citep{cerniglia2015inspection}.

There are various discontinuities in AM, in particular in the manufacturing of metal parts \citep{everton2016review}. For example gas can become trapped during the manufacturing process forming gas pores in the manufactured object \citep{thijs2010study, tammas2015xct}; they can be \SIrange{5}{20}{\micro\metre} in diameter \citep{everton2016review}. Layers may not fuse together and form elongated pores, this can be fixed by increasing the energy of the beam but too high will cause evaporation of the AM part \citep{mumtaz2008high}. They can be \SIrange{50}{500}{\micro\metre} in size \citep{everton2016review}. Low wetting ability of the melt pool can cause balling, this is where the sintered powder has poor contact on the existing layer causing spherical particles on the surface of the AM part \citep{li2012balling, gu2009balling}. The spherical particles can vary in size of \SIrange{10}{500}{\micro\metre} \citep{li2012balling}. Low oxygen content in the environment \citep{niu1999instability} and higher energy beams \citep{gu2009balling} can reduce the balling effect. Cracks can form due to extreme temperature changes and gradients \citep{mercelis2006residual, zaeh2010investigations}.

Various methods are used for in-situ process monitoring. Most commonly a high speed camera is installed capturing the various wavelengths in the electromagnetic spectrum emitted by the melt pool \citep{berumen2010quality, craeghs2011online, lott2011design}. Various discontinuities and errors can be detected \citep{clijsters2014in} and be used to give feedback to the AM apparatus \citep{herzog2013method}. Other methods include measuring the surface using a laser \citep{cerniglia2015inspection} and using an infrared camera to measure the temperature of the melt pool \citep{rodriguez2012integration}. 

\section{X-ray Computed Tomography}

XCT started its use in the medical field but advancement of the technology saw its use in manufacturing and metrology, the science of measurement. Applications of XCT include the examination of acetabular hip prosthesis cups \citep{kourra2018computed}, skeletons \citep{appleby2014scoliosis}, batteries \citep{taiwo2017investigating} and materials \citep{zhang2016x, wang2017x}. Reverse engineering is possible when XCT is combined with AM, for example it was use for improving existing hollow engine valves \citep{cooper2015design}. However the use of XCT in metrology is not yet firmly established compared to other methods of measurement \citep{thompson2016x}. This is because is a lot of inconsistent in the setup of XCT apparatuses and on controlling the sources of error.

\subsection{Concepts from the Medical Field}

The setup of XCT \citep{cormack1973reconstruction, hounsfield1973computerized, hounsfield1980computed} in the medical field involves the patient laying on a bed. An x-ray source and x-ray detector pair rotate and/or translate around and/or along the patient to get readings of the x-rays after attenuating the patient using different paths. X-ray beams are pencil beams in the early versions of XCT. To reduce scanning times, cone shaped beams and arrays of detectors were used and they can move in a spiral fashion along and around the patient \citep{cierniak2011x}. These multiple x-ray readings or images can be used to reconstruct a representation of the patient in 3D \citep{zeng2010medical}.

The patient cannot be exposed to too much radiation, therefore the x-rays used are of low power. This can cause noisy readings from the detector. The sources of noise are from the behaviour of the x-rays and from the electronics in the detector \citep{yang2010noise}. In this realm of low signal to noise ratio, the noise has a compound Poisson element to it \citep{whiting2002signal, whiting2006properties}. Many reconstruction algorithms have been proposed to take the compound Poisson noise into consideration \citep{elbakri2002statistical, elbakri2003efficient, elbakri2003statistical, lasio2007statistical, xie2008x}. They are very complicated will not be discussed here because they are beyond the scope of this thesis.

\subsection{Acquisition Process}

Higher power x-rays can be used in XCT for the purpose of manufacturing and metrology because there is no consequence of the manufactured object being scanned absorbing the radiation. The XCT setup is different, the object is held by foam on a turntable and placed between an x-ray source and an x-ray detector. X-ray images are taken while the object rotates. Typically the x-ray is a cone beam \citep{kruth2011computed}.

The acquisition process consist of the production of x-rays, x-ray attenuating the object, the detection of x-rays and the reconstruction process.

X-rays \citep{rontgen1896on} are produced in an x-ray tube. It consist of a vacuum tube containing a cathode and an anode. Electrons are fired from the cathode to the anode due to an electric potential. The cathode is usually tungsten and the anode contains a small amount of tungsten, molybdenum or copper \citep{sun2012overview}.

The electrons can interact with the anode in a number of ways. The electrons can be deflected or decelerated due to the electric field from the nucleus of the target material, the energy lost by the electrons is emitted as bremsstrahlung radiation. The energy of the bremsstrahlung radiation depends on the potential difference in the x-ray tube, as this determines the energy of the fired electrons, and also the proton number of the anode target because this affects the electric field produced by the nucleus in the anode target \citep{sun2012overview}. Another interaction is when the electrons may collide with the nucleus in the anode target, exciting an inner shell electron and ionizing it. This produce a vacancy in the electron shell and emits a photon when the excited electron drops down back to the ground state. This is known as characteristic radiation and the energy emitted is discrete and depends on the material in the anode target.

The efficiency of an x-ray tube is poor, 99\% of the electron energy is converted to heat, the rest on x-rays \citep{kruth2011computed}.

Photons are emitted from the x-ray tube as a Poisson process. The rate of x-ray emission depends on the current, that is the rate of charge between the cathode and anode. The energy of each photon are from bremsstrahlung radiation and characteristic radiation, making the distribution of x-ray photons energy a mix of continuous and discrete energies.

The object being scanned are being exposed x-ray photons in XCT. X-ray photons undergo attenuation when interacting with the object in a number of ways. The object can absorb the photons via the photoelectric effect. In the photoelectric effect, the photons transfers all its energy to a bounded electron and ejects it from the sample's atom \citep{millikan1916direct}. Photons can be scattered by the sample by colliding inelastically with and transfers its energy to the an electron. This process is known as Compton scattering \citep{compton1923quantum}. The photoelectric effect and Compton scattering make a number of photons undetectable. However if some of the photons avoid these processes, they are detected and their energy is left unaffected.

Beer's law simplifies these quantum mechanistic process. Suppose the x-ray beam with rate of emission $I_0$ is mono-energetic and travels in a straight line in the $x$-axis. Let $\mu=\mu(x)$ be the attenuation coefficient of the object and the x-ray beam has rate of emission $I$ after attenuation. A differential equation can be setup such that
\begin{equation}
\dfrac{\diff I}{\diff x} = -I\mu(x)
\end{equation}
which can be solved
\begin{equation}
I = I_0\exp\left[\int_{\text{path of photon}}-\mu(x)\diff x\right] \ .
\label{eq:beerLaw}
\end{equation}
However the photoelectric effect and Compton scattering, thus the attenuation coefficient as well, depends on the energy of the photons \citep{elbakri2002statistical}. Therefore $\mu=\mu(x,E)$ should be made dependent on the energy of the photons \citep{cantatore2011introduction}. In general low energy photons are more likely to be absorbed and scattered than high energy photons, this increases the average energy of the attenuated photons. This is called beam hardening.

After attenuation, the x-ray photons are detected by the x-ray detector. Most X-ray detectors are made up of a scintillator material \citep{curran1953luminescence, greskovich1997ceramic} and photodiodes. The x-ray photons interact with the scintiallator material and produce visible light \citep{rossner1993conversion}. The visible light is detected by photodiodes and covert it into electrical signal \citep{michael2001x}. The electrical signal can be a quantum counter, counting the number of photons detected, or an energy integrating detector, adding up all of the energies of each detected photon \citep{whiting2006properties, kruth2011computed}.

Not all of the visible light photons are detected by the photodiodes, thus not all the x-ray photons are detected. The ratio between the number of x-ray photons detected by the detector and the number of x-ray photons arriving at the detector is called the quantum efficiency \citep{cierniak2011x}.

The detection is a two stage process \citep{cierniak2011x}, although there exist equipment which detects x-ray directly such as a xenon gas ionization detector \citep{fuchs2000direct}, solid state CT systems such as sintillator-photodiodes detectors have high quantum efficiency of about 98\% to 99.5\% \citep{hsieh2000investigation}. The detectors used in CT scanning are typically flat bed scanners which consist of an array of panels of photodiodes \citep{cantatore2011introduction}. The electrical signal from the photodiodes are subject to sampling and quantisation to store these signals as an image \citep{cierniak2011x}.

%DEAD PIXELS, PANELS

Methods used to reconstruct the 3D surface of the sample are available such as filtered back-projection \citep{brooks1976principles} and the FDK algorithm \citep{feldkamp1984practical}. There exist software such as \emph{VGStudio MAX} \citep{reinhart2008industrial} which automatically aligns and scales the 3D reconstruction with the computed aided design and compares them.

Reconstruction \citep{radon1986on} There exist various reconstruction algorithms \citep{smith1990cone}

\subsection{Metrology}

\subsection{Latest Research}

\subsection{X-Ray Production}
Photons in CT scanning are produced in an X-ray tube. In an X-ray tube, a cathode, consisting of a heated filament, fires projectile electrons through an electric potential to a target which forms the anode \citep{michael2001x}, as shown in Figure \ref{fig:x_ray_tube}. Most of the kinetic energy of the projectile electrons is converted into heat however some is converted into electromagnetic radiation. This depends on how the projectile electrons interact with the atoms in the anode \citep{cantatore2011introduction}.

\begin{figure}
	\centering
	\includegraphics[width=0.8\textwidth]{figures/x_ray_tube.png}
	\caption{An X-ray tube produces photons by firing projectile electrons from a cathode to an anode. \citep{michael2001x}}
	\label{fig:x_ray_tube}
\end{figure}

Bremsstrahlung is the result of projectile electrons deaccelerating due to the electrostatic field produced by nucleus of the target. The kinetic energy of the projectile electrons is then converted to electromagnetic radiation to produce X-ray radiation. As a result, the photon energies in bremsstrahlung radiation is  a continuous spectrum and can range up to the maximum kinetic energy of the projectile electrons \citep{michael2001x}.

Characteristic radiation is due to projectile electrons colliding with electrons in the target atom and ionizing them. This produce vacancies in the electron shell and emits photons when the electrons in the target atom drops down back to the ground state. The energy of the emitted radiation is monoenergetic and depends on the binding energy of the target's atoms \citep{michael2001x}.

A typical energy spectrum of photons emitted from an X-ray tube is as shown in Figure \ref{fig:x_ray_spectrum}. The energy spectrum consist of both bremsstrahlung and characteristic radiation \citep{michael2001x}.

\begin{figure}
	\centering
	\includegraphics[width=0.8\textwidth]{figures/x_ray_spectrum.png}
	\caption{A typical energy spectrum of photons emitted from an X-ray tube. The continuous spectrum is the result of bremmsstrahlung. The peaks are the result of characteristic radiation. \citep{michael2001x}}
	\label{fig:x_ray_spectrum}
\end{figure}

The voltage and current can be varied in the X-ray tube to produce different energy spectrums and rate of photon production. This can vary the results produced when collecting CT data \citep{cantatore2011introduction}. Another important factor is the focal spot size because smaller spot sizes produce sharper edges. Larger spot sizes produce unsharp results and this is know as the penumbra effect, as shown in Figure \ref{fig:x_ray_penumbra}. However spot sizes too small can produce concentrated heat \citep{welkenhuyzen2009industrial} and can damage the X-ray tube.

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/x_ray_penumbra.png}
	\caption{Larger focal spot sizes produces unsharp results. This is know as the penumbra effect. \emph{Source: F.~Welkenhuyzen et al.~(2009)\citep{welkenhuyzen2009industrial}}}
	\label{fig:x_ray_penumbra}
\end{figure}

\subsection{Photon Interactions}
Photons emitted by the X-ray tube are projected onto the sample and interacts with it in a number of ways \citep{cantatore2011introduction}.

The sample can effectively absorb photons via the photoelectric effect or pair production \citep{cantatore2011introduction}. In the photoelectric effect, the photons transfers all its energy to a bounded electron and ejects it from the sample's atom \citep{millikan1916direct}. In pair production, the photons convert into electron-position pairs by interacting with the Coulomb field of the sample's atomic nucleus \citep{hubbell2006electron}. In addition to getting absorbed, photons can be scattered by the sample. This happens when photons collide inelastically with and transfers its energy to the sample's electrons. This process is known as Compton scattering \citep{compton1923quantum}.

Suppose a mono-energetic X-ray pencil beam attenuating through an object with varying attenuation coefficient in position $\mu=\mu(x)$. The beam starts at $x=0$ and is detected at $x=L$, then the attenuation (decrease in X-ray intensity from $I_0$ to $I_1$) is given as \citep{cantatore2011introduction}
\begin{equation}
	I_1 = I_0\exp\left[\int_0^L-\mu(x)\diff x\right].\label{eq:beerLaw}
\end{equation}
By comparing the intensity before and after attenuation, the integral of the attenuation coefficient along the path of the X-ray can be calculated. Because of the discrete nature of pixels, the integral is usually replaced by a sum \citep{michael2001x}. 

However it was shown that the attenuation coefficient does depend on the energy of the photons \citep{elbakri2002statistical}. Thus $\mu=\mu(x,E)$ should be made dependent on the energy of the photons \citep{cantatore2011introduction}. In general low energy photons are more likely to be absorbed than high energy photons, this increases the average energy of the attenuated photons and can be a source of error in CT scanning. This is referred to beam hardening and can cause inaccuracies in Equation \eqref{eq:beerLaw} \citep{michael2001x}. This can be reduced by placing a thin sheet of filter to absorb low energy photons \citep{welkenhuyzen2009industrial} or by correcting it in the data analysis stage \citep{michael2001x}.


\subsection{Detection}
Most X-ray detectors are made up of a scintillator material \citep{greskovich1997ceramic} and photodiodes. Firstly the x-ray photons interact with the scintiallator material and produce visible light \citep{rossner1993conversion}. Lastly the visible light is then detected by photodiodes and coverts it into electricical current \citep{michael2001x}. Not all of the visible light photons are detected by the photodiodes, thus not all the x-ray photons are detected. The ratio between the number of x-ray photons detected by the detector and the number of x-ray photons arriving at the detector is called the quantum efficiency \citep{cierniak2011x}.

The detection is a two stage process \citep{cierniak2011x}, although there exist equipment which detects x-ray directly such as a xenon gas ionization detector \citep{fuchs2000direct}, solid state CT systems such as sintillator-photodiodes detectors have high quantum efficiency of about 98\% to 99.5\% \citep{hsieh2000investigation}. The detectors used in CT scanning are typically flat bed scanners which consist of an array of panels of photodiodes \citep{cantatore2011introduction}. The electrical signal from the photodiodes are subject to sampling and quantisation to store these signals as an image on a computer \citep{cierniak2011x}.

\section{X-ray Computed Tomography}
Computed tomography (CT) scanning is a 3D imaging technique. It does this by reconstructing the geometry of the sample through a series of 2D X-ray images of the sample. The sample rotates after each image taken \citep{cantatore2011introduction}.

Figure \ref{fig:x_ray_ct} shows a diagram on how CT scanning works. A 2D image is taken by projecting X-ray photons onto the stationary sample. The photons are then scattered or absobred by the sample.  Some of these photons are then detected by an X-ray detector on the other side of the sample, which produces an image. After an image has been taken, the object rotates and another image is taken. Finally after a number of images, a 3D reconstruction of the object can be estimated \citep{cantatore2011introduction}.

\begin{figure}
	\centering
	\includegraphics[width=0.7\textwidth]{figures/x_ray_ct.png}
	\caption{X-ray computed tomography reconstructs the sample by projecting photons onto a rotating sample. The photons are then detected by the detector. \emph{Source: \url{http://www.phoenix-xray.com/}}}
	\label{fig:x_ray_ct}
\end{figure}

CT was solved theoretically by \cite{cormack1973reconstruction} and implemented by \cite{hounsfield1973computerized} \citep{hounsfield1980computed}. It was mainly used for medical imaging. The setup for CT scanning is different when scanning patients because the detector and X-ray source rotates around the patient \citep{cantatore2011introduction}. Recently CT has been used industrially for non-destructive testing in manufacturing \citep{cantatore2011introduction}. One possible application would be inspecting 3D printed samples \citep{villarraga2015assessing}. Other uses in science include the investigation of batteries \citep{o2017investigating} and materials \citep{wang2017x} \citep{zhang2016x}.

Methods used to reconstruct the 3D surface of the sample are available such as filtered back-projection \citep{brooks1976principles} and the FDK algorithm \citep{feldkamp1984practical}. There exist software such as \emph{VGStudio MAX} \citep{reinhart2008industrial} which automatically aligns and scales the 3D reconstruction with the computed aided design and compares them.

Studies have been done to use x-ray CT to do defection detection on 3D printing \citep{kim2016inspection} \citep{villarraga2015assessing}. This was done by investigating the variation of the material thickness and the distribution of the volume of voids \citep{villarraga2015assessing}. Voids then can be classified as defects if the voids are larger than some volume threshold. This threshold controls the probability of the detection of defects \citep{amrhein2014characterization} \citep{gandossi2010probability}.

Full 3D x-ray CT scans can be slow and may not generalised well in production lines. However there is potential to bring in methods such as those used in airport luggage inspection to speed up to process \citep{warnett2016towards}.

There are many sources of error in CT scanning \citep{cantatore2011introduction} and this can cause problems when reconstructing the geometry of the sample. Sources of error include: dead pixels in the detector \citep{brettschneider2014spatial}, use of cone beams \citep{sun2016applications}, beam hardening and the orientation of the sample \citep{corcoran2016observations}.

The scale of the 2D images can be calibrated with the use of reference standards \citep{bartscher2007enhancement} \citep{lifton2013application}.

\section{Compound Poisson}

The greyvalues of each pixel in the detector can be modelled as a random variable, due to the random behaviour of photons being produced, interacting with the phantom and interacting with the scintillator in the detector. When the photons interact with the scintillator, they are converted into visible light. The visible light photons are then detected and converted into a greyvalue. How the detected visible light is converted is important in modelling the greyvalue.

Should the greyvalue be proportional to the number of photons detected, the detector is known as a quantum counter and the greyvalue is a Poisson random variable, up to a constant \citep{whiting2006properties}. However if the greyvalue records the signal strength, proportional to the energy detected, then the detector is an energy integrating detector. The greyvalue has the compound Poisson distribution, again up to a constant \citep{whiting2006properties}. There are other types of detection schemes \citep{whiting2006properties} but it shall be not be considered here.

Experiments have been done to verify the compound Poisson nature of the detector. This was done by investigating the variance of radiographs of air \citep{hsieh2015compound} and a polyethylene cylinder \citep{yang2009evaluation} \citep{yang2010noise} at different voltages and powers. It was found there were 2 components in the noise, one was signal dependent and comes from the compound Poisson, the other was signal independent and may be electronic noise. The electronic noise can be modelled as Normally distributed \citep{xu2009electronic}.

The compound Poisson can be formally written. Let $Y$ be the number of photons detected in a pixel for some time exposure $\tau$,
\begin{equation*}
	Y\sim\poisson(\lambda)
\end{equation*}
that is
\begin{equation*}
	\prob(Y=y)=\euler^{-\lambda}\frac{\lambda^y}{y!} \quad \text{for }y=0,1,2,\dotdotdot
\end{equation*}
where $\lambda>0$ is the Poisson rate parameter. Let $U_i$ be the energy of the $i$th photon in a pixel for i.i.d.~$i=1,2,3,\dotdotdot$ with p.d.f.~$p_U(u)$. Let $X$ be the greyvalue of a pixel and is an energy integrating detector, then
\begin{equation}
	X|Y = \sum_{i=1}^{Y}U_i+\kappa
	\label{eq:compoundPoisson_X|Y}
\end{equation}
where $\kappa$ is some offset. For now let $\kappa=0$, then the marginal $X$ has the compound Poisson distribution. The p.d.f.~of $X$ can be obtained by marginalising the joint p.d.f.
\begin{equation*}
	p_X(x)=\sum_{y=0}^\infty p_{X|Y}(x|y)\prob(Y=y) \quad\text{for }x\geqslant 0
	\ .
\end{equation*}
However it should be noted that $X=0$ if and only if $Y=0$ with probability
\begin{equation*}
	\prob(X=0)=\euler^{-\lambda} \ .
\end{equation*}
Formally $X$ has probability mass at $X=0$ and probability density at $X>0$, then 
\begin{equation}
	p_X(x) = 
	\begin{cases}
		\delta(x) \euler^{-\lambda}  & \text{ for } x=0 \\ 
		\sum_{y=1}^\infty p_{X|Y}(x|y)\euler^{-\lambda}\frac{\lambda^y}{y!} \quad\text{for } & \text{ for } x>0
	\end{cases}
\end{equation}
where $\delta(x)$ is the Dirac delta function. It is quite often the case this cannot be written in closed form.

The m.g.f.~of $X$ has a nicer form however. Let the m.g.f.~of $X$ be
\begin{equation*}
	M_X(\theta)=\expectation\left[\euler^{X\theta}\right]
	\ .
\end{equation*}
This can be computed using the result for conditional expectations
\begin{equation*}
	M_X(\theta)=\expectation\expectation\left[\euler^{X\theta}|Y\right]
	\ .
\end{equation*}
Using the definition of $X|Y$ in Equation \eqref{eq:compoundPoisson_X|Y}, then
\begin{equation*}
	M_X(\theta)=\expectation\expectation\left[\exp\left(\theta U_1 + \theta U_2 + \dotdotdot + \theta U_Y\right)|Y\right]
\end{equation*}
\begin{equation*}
	M_X(\theta)=\expectation\expectation\left[\euler^{\theta U_1}\cdot\euler^{\theta U_2}\cdot\dotdotdot\cdot\euler^{\theta U_Y}|Y\right]
	\ .
\end{equation*}
But because $U_i$ for $i=1,2,3,\dotdotdot$ are i.i.d., then each $U_i$ has a common m.g.f.
\begin{equation*}
	M_U(\theta)=\expectation\left[\euler^{U\theta}\right]
	\ ,
\end{equation*}
then
\begin{equation*}
	M_X(\theta)=\expectation\left(
		\expectation\left[\euler^{\theta U_1}|Y\right]\cdot
		\expectation\left[\euler^{\theta U_2}|Y\right]\cdot
		\dotdotdot \cdot
		\expectation\left[\euler^{\theta U_Y}|Y\right]
	\right)
\end{equation*}
\begin{equation*}
	M_X(\theta)=\expectation\left[\left(M_U(\theta)\right)^Y\right]
\end{equation*}
\begin{equation*}
	M_X(\theta)=\expectation\left[\euler^{Y\ln(M_U(\theta))}\right]
\end{equation*}
\begin{equation*}
	M_X(\theta) = M_Y\left(\ln(M_U(\theta)\right)
\end{equation*}
where $M_Y(\theta)$ is the m.g.f.~of $Y$. It can be shown that the m.g.f.~of $Y$ is
\begin{equation}
	M_Y(\theta)=\expectation\left[\euler^{Y\theta}\right]=
	\exp
	\left[
		\lambda
		\left(
		  \euler^\theta-1
		\right)
	\right]
\end{equation}
then
\begin{equation}
	M_X(\theta)=
	\exp\left[
		\lambda
		\left(
			M_U(\theta)-1
		\right)
	\right]
	\ .
\end{equation}
As long as the m.g.f.~of $U$ is known, then m.g.f.~of $X$ can be written in closed form.

Moments of $X$ can be obtained from the m.g.f.~by differentiating it and setting it to zero
\begin{align*}
	M_X'(\theta)&=\exp\left[\lambda\left(M_U(\theta)-1\right)\right]\cdot\lambda M_U'(\theta) \\
	M_X'(\theta)&=M_X(\theta)\lambda M_U'(\theta)
\end{align*}
then
\begin{equation}
	\expectation\left[X\right]=\lambda\expectation\left[U\right]
	\ .
\end{equation}
Conducting the same procedure
\begin{equation*}
	M_X''(\theta)=M_X'(\theta)\lambda M_U'(\theta)+M_X(\theta)\lambda M_U''(\theta)
	\ ,
\end{equation*}
the variance can be obtained
\begin{equation*}
	\variance\left[X\right]=M_X''(0)-\left[M_X'(0)\right]^2
\end{equation*}
\begin{equation*}
	\variance\left[X\right]=M_X'(0)\lambda M_U'(0)+M_X(0)\lambda M_U''(0)-\left[\lambda\expectation\left[U\right]\right]^2
\end{equation*}
\begin{equation*}
	\variance\left[X\right]=\lambda^2 \left(\expectation\left[U\right]\right)^2+\lambda \expectation\left[U^2\right]-\left[\lambda\expectation\left[U\right]\right]^2
\end{equation*}
resulting in
\begin{equation}
	\variance\left[X\right] = \lambda\expectation\left[U^2\right]
	\ .
\end{equation}
This can be extended for higher moments.

Because the m.g.f.~can be written down in closed form, so is the characterisation function or Fourier transform of the p.d.f.~of $X$. By obtaining an empirical version of $p_U(u)$, moments of $X$ can be estimated using the m.g.f.~and the p.d.f.~can be estimated by using fast Fourier transform on the empirical characteristic function \citep{whiting2006properties}.

If the distribution of $U$ cannot be obtained or estimated, then one can guess that distribution. \cite{xu2009electronic} for example used a Gamma distribution
\begin{equation}
	U\sim\gammaDist\left(\alpha,\beta\right)
\end{equation}
where $\alpha>0$ is the Gamma shape parameter and $\beta>0$ is the Gamma rate parameter. This is a special case of the compound Poisson called the compound Poisson-Gamma model and one can write
\begin{equation}
	X\sim\CPoisson(\lambda,\alpha,\beta)
	\ .
\end{equation}
The conditional distribution can be shown to be
\begin{equation}
	X|Y\sim\gammaDist\left(Y\alpha,\beta\right)
	\ .
\end{equation}

Using results derived earlier, the m.g.f.~of the of $X$ is
\begin{equation}
	M_X(\theta)=\exp\left[\lambda\left(\left(\frac{\beta}{\beta-\theta}\right)^{\alpha}-1\right)\right]
\end{equation}
and moments can be obtained from it such as
\begin{equation}
	\expectation\left[X\right]=\frac{\alpha\lambda}{\beta}
\end{equation}
\begin{equation}
	\variance\left[X\right]=\frac{\alpha(\alpha+1)\lambda}{\beta^2}
	\label{eq:compoundPoisson_variance}
\end{equation}
and
\begin{equation}
	\expectation\left[(X-\expectation[X])^3\right] = \frac{\alpha(\alpha+1)(\alpha+2)\lambda}{\beta^3}
	\ .
\end{equation}

The p.d.f.~can be shown to be
\begin{equation}
	p_X(x) = 
	\begin{cases}
		\delta(x) \euler^{-\lambda} & \text{ for } x=0 \\ 
		\sum_{y=1}^{\infty}\frac{\beta^{y\alpha}}{\Gamma(y\alpha)}x^{y\alpha-1}\euler^{-\beta x}\euler^{-\lambda}\frac{\lambda^y}{y!} & \text{ for } x>0
	\end{cases}
	\label{eq:compoundPoisson_pdf}
\end{equation}
and it is well known the infinite sum cannot be written in closed form. There are a number of approximations or computational methods to evaluate the p.d.f.~such as Fourier inverting the characteristic function \citep{dunn2008evaluation}, using the saddlepoint approximation \citep{daniels1954saddlepoint} or cleverly sum over certain terms in the infinite sum \citep{dunn2005series}. Of course direct simulation of a compound Poisson-Gamma random variable is incredibly easy if $U$ can be simulated. The p.d.f.~then can be estimated using these simulated samples.

For a given i.i.d.~random sample of a compound Poisson-Gamma random variable, parameter estimation can be difficult. Maximum likelihood estimation is very complicated \citep{withers2011compound}. It can be made simpler by fixing $\alpha$ to be known \citep{withers2011compound} but this is not useful in this context.

Because the moments of a compound Poisson-Gamma random variable can be obtained easily, method of moments estimators can be obtained. Suppose $\widehat{\mu}$ is an estimator of $\expectation[X]$ and $\widehat{\mu}_j$ is an estimator of $\expectation\left[\left(X-\expectation[X]\right)^j\right]$ for $j=2,3$. Then the estimators
\begin{equation}
	\widehat{\lambda}=\frac{\widehat{\mu}^2\widehat{\mu}_2}{\left(2\widehat{\mu}_2^2-\widehat{\mu}_3\widehat{\mu}\right)}
\end{equation}
\begin{equation}
	\widehat{\alpha}=\frac{\widehat{\mu}_3\widehat{\mu}-2\widehat{\mu}_2^2}{\widehat{\mu}_2^2-\widehat{\mu}\widehat{\mu}_3}
\end{equation}
\begin{equation}
	\widehat{\beta}=\frac{\widehat{\mu}\widehat{\mu}_2}{\widehat{\mu}\widehat{\mu}_3-\widehat{\mu}_2^2}
\end{equation}
are method of moments estimators of $\lambda$, $\alpha$ and $\beta$ respectively \citep{withers2011compound}. These estimators suffer because estimation is not done through the sufficient statistics and can be negative, this is a problem because the parameters do not take non-positive values.

However, parameter estimation can be made easier once it can be realised that the compound Poisson-Gamma distribution is in the exponential family for fixed $\alpha$ \citep{jorgensen1987exponential}. To show this, it is particular useful to reparametrize the compound Poisson-Gamma distribution using the following:
\begin{equation}
	p=\frac{2+\alpha}{1+\alpha}
	\ ,
\end{equation}
\begin{equation}
	\mu=\frac{\lambda\alpha}{\beta}
	\ ,
\end{equation}
\begin{equation}
	\phi = \frac{\alpha+1}{\beta^{2-p}(\lambda\alpha)^{p-1}}
	\ .
\end{equation}
The parameters $p$, $\mu$ and $\phi$ are called the index, mean and dispersion parameters respectively. It can be shown that $1<p<2$, $\mu>0$ and $\phi>0$.

By rearranging the parameters to get
\begin{equation}
	\lambda=\frac{\mu^{2-p}}{\phi(2-p)}
\end{equation}
\begin{equation}
	\alpha=\frac{2-p}{p-1}
\end{equation}
\begin{equation}
	beta=\frac{1}{\phi(p-1)\mu^{p-1}}
\end{equation}
and substituting it into Equation \eqref{eq:compoundPoisson_pdf}, the p.m.f.~at zero can be shown to be
\begin{equation}
	\prob(X=0) = \exp
	\left[
	    -\frac{\mu^{2-p}}{\phi(2-p)}
	\right]
\end{equation}
and the p.d.f.~for $x>0$ is
\begin{multline*}
	p_X(x) = \sum_{y=1}^{\infty}
	\left[
		\frac{1}{\phi(p-1)\mu^{p-1}}
	\right]^{y\alpha}
	\frac{1}{\Gamma(y\alpha)}
	x^{y\alpha-1}
	\exp\left[
	    -\frac{x}{\phi(p-1)\mu^{p-1}}
	\right]
	\\
	\exp\left[
	    -\frac{\mu^{2-p}}{\phi(2-p)}
	\right]
	\left[
		\frac{\mu^{2-p}}{\phi(2-p)}
	\right]^y
	\frac{1}{y!}
	\ .
\end{multline*}
Tidying up the equation
\begin{multline*}
	p_X(x) = 
	\exp\left[
		\frac{1}{\phi}\left(x\frac{\mu^{1-p}}{1-p}-\frac{\mu^{2-p}}{2-p}\right)
	\right]
	\frac{1}{x}
	\\
	\sum_{y=1}^{\infty}\frac{x^{y\alpha}\mu^{y[2-p-\alpha(p-1)]}}{\phi^{y(1+\alpha)}(p-1)^{y\alpha}(2-p)^yy!\Gamma(y\alpha)}
	\ .
\end{multline*}
To simplify further, it should be noted that
\begin{align*}
	2-p-\alpha(p-1) &= 2-p - \frac{2-p}{p-1}(p-1)
	\\&=0
\end{align*}
so that
\begin{equation}
	p_X(x) = 
	\exp\left[
		\frac{1}{\phi}
		\left(
			x\frac{\mu^{1-p}}{1-p}-\frac{\mu^{2-p}}{2-p}
		\right)
	\right]
	\frac{1}{x}
	\sum_{y=1}^{\infty}W_y(x,p,\phi)
\end{equation}
where
\begin{equation}
	W_y(x,p,\phi)=\frac{x^{y\alpha}}{\phi^{y(1+\alpha)}(p-1)^{y\alpha}(2-p)^yy!\Gamma(y\alpha)}
	\ .
\end{equation}

Those familiar with generalised linear models \citep{nelder1972generalized} \citep{mccullagh1984generalized} will notice that for fixed $p$ or $\alpha$, the above is in the form of a distribution in the dispersive exponential family. Parameter estimation then can be done via the generalised linear model framework and can be extended to include linear mixed models \citep{zhang2013likelihood}. These has applications in for example insurance claim data \citep{jorgensen1994fitting} \citep{smyth2002fitting}.

Estimating $p$ is difficult and various methods were discussed by \cite{zhang2013likelihood}. One easy way is to estimate $\mu$ and $\phi$ on a grid of $p$'s and then select the $p$ which maximises the likelihood \citep{dunn2005series}.

One special property of the compound Poisson-Gamma distribution is that it is in the Tweedie dispersion exponential family \citep{jorgensen1987exponential}. It has a special variance mean relationship
\begin{equation}
	\variance[X] = \phi \mu^p
\end{equation}
where, as a reminder, $1<p<2$. This can be derived using Equation \eqref{eq:compoundPoisson_variance} or via the partition function $Z$. That is let
\begin{equation}
	\theta = \frac{\mu^{1-p}}{1-p}
\end{equation}
and
\begin{equation}
	\ln Z = \frac{1}{\phi(2-p)\theta^\alpha(1-p)^\alpha} \ ,
\end{equation}
then
\begin{equation}
	\variance[X] = \phi^2 \frac{\partial^2\ln Z}{\partial\theta^2} \ .
\end{equation}